{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define function to extract data from file, Load training data and convert into Numpy array\n",
    "def get_data(file_name):\n",
    "    df_input=pd.read_csv(file_name,usecols =['T1','T2','T_out','Press_mm_hg','Windspeed'])\n",
    "    #'RH_out','T3', 'T4','Visibility','Tdewpoint'\n",
    "    df_target=pd.read_csv(file_name,usecols =['Appliances'])\n",
    "    print(df_input.head())       #Print first few columns of input data\n",
    "    print(df_target.head())      #Print first few columns of target data\n",
    "    #print(df_input.info())\n",
    "    #print(df_target.info())\n",
    "    X_data = df_input.as_matrix()\n",
    "    y_data = df_target.as_matrix()\n",
    "    X_data.astype('float32', copy=False)\n",
    "    y_data.astype('float32', copy=False)\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split( X_data, y_data,test_size=0.20)  #function to split data set\n",
    "    \n",
    "    \n",
    "    return X_train,y_train,X_valid,y_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      T1    T2  T_out  Press_mm_hg  Windspeed\n",
      "0  19.89  19.2   6.60        733.5   7.000000\n",
      "1  19.89  19.2   6.48        733.6   6.666667\n",
      "2  19.89  19.2   6.37        733.7   6.333333\n",
      "3  19.89  19.2   6.25        733.8   6.000000\n",
      "4  19.89  19.2   6.13        733.9   5.666667\n",
      "   Appliances\n",
      "0          60\n",
      "1          60\n",
      "2          50\n",
      "3          50\n",
      "4          60\n",
      "Shape of training input data set (15788, 5)\n",
      "Shape of training target data set (15788, 1)\n",
      "Number of training samples: 15788\n",
      "Shape of validation input data set (3947, 5)\n",
      "Shape of validation target data set (3947, 1)\n"
     ]
    }
   ],
   "source": [
    "#Get training data\n",
    "file_name = './Appliances_energy_prediction_data_set_UCI.csv'\n",
    "X_train,y_train,X_valid,y_valid = get_data(file_name)\n",
    "print('Shape of training input data set',X_train.shape)\n",
    "print('Shape of training target data set',y_train.shape)\n",
    "print('Number of training samples:',len(X_train))\n",
    "print('Shape of validation input data set',X_valid.shape)\n",
    "print('Shape of validation target data set',y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to normalize input data along features\n",
    "def normalize_data(raw_data):\n",
    "    import tensorflow as tf\n",
    "    return tf.nn.l2_normalize(raw_data,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training parametres\n",
    "epochs = 10     #Number of times to peform training\n",
    "display_epoch = 2  \n",
    "learning_rate = 0.001  #The rate at which weights are updated in the neural network\n",
    "mini_batch_size = 100  #The size to which the training data is split up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Network Parameteres\n",
    "L1 = 10 # Number of neurons in Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Placeholders for input and output\n",
    "Xfeatures = 5  #Number of features in input data\n",
    "Yfeatures =1    #Number of features in target data\n",
    "#Input\n",
    "X = tf.placeholder(tf.float32,shape=(None,Xfeatures))#Place holder for input data\n",
    "#Output\n",
    "Y = tf.placeholder(tf.float32,shape=(None,Yfeatures))   #Place holder for target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Builda single layer model using core TensorFlow operations\n",
    "def FFNN_using_core(Xinput):          #Function containing FFNN model\n",
    "    #Layer1 \n",
    "    W_fc1 = tf.Variable(tf.random_uniform([Xfeatures,L1])) # Weights\n",
    "    b_fc1 = tf.Variable(tf.random_uniform([L1]))        #Biases\n",
    "    matmul_fc1=tf.matmul(Xinput, W_fc1) + b_fc1                #Matrix multiplication and addition\n",
    "    h_fc1 = tf.nn.relu(matmul_fc1)   #ReLU activation function\n",
    "\n",
    "    #Output layer \n",
    "    W_fO= tf.Variable(tf.random_uniform([L1,Yfeatures])) # Weights\n",
    "    b_fO = tf.Variable(tf.random_uniform([Yfeatures]))    #Biases\n",
    "    matmul_fcO=tf.matmul(h_fc1, W_fO) + b_fO    #Matrix multiplication and additon\n",
    "    output_layer = matmul_fcO  #linear activation\n",
    "    return output_layer\n",
    "\n",
    "prediction1 = FFNN_using_core(normalize_data(X))       #Call function containing for model\n",
    "#prediction = FFNN_using_core(X)       #Call function\n",
    "MAE1= tf.metrics.mean_absolute_error(Y,prediction1)   #Function to calculate mean absolute error \n",
    "\n",
    "#Loss function\n",
    "loss1 = tf.reduce_mean(tf.square(Y-prediction1))\n",
    "\n",
    "#Specify optimizer\n",
    "train_step1 = tf.train.AdamOptimizer(learning_rate).minimize(loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Build single layer model using TensorFlow layers\n",
    "def FFNN_using_layer(Xinput):          #Function containing FFNN model\n",
    "    #Layer1 \n",
    "    FC1 = tf.layers.dense(Xinput,L1,activation=tf.nn.relu)   #Add a feed forward layer\n",
    "\n",
    "    #Output layer \n",
    "    output_layer = tf.layers.dense(FC1,Yfeatures)\n",
    "    return output_layer\n",
    "\n",
    "prediction2 = FFNN_using_layer(normalize_data(X))       #Call function\n",
    "#prediction = FFNN_using_layer(X)       #Call function\n",
    "MAE2= tf.metrics.mean_absolute_error(Y,prediction2)\n",
    "#Specify Loss function\n",
    "loss2 = tf.losses.mean_squared_error (Y,prediction2)\n",
    "#Specify optimizer\n",
    "train_step2 = tf.train.AdamOptimizer(learning_rate).minimize(loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (Mean squre error) at epoch 1:18851.4140625\n",
      "Validation loss (Mean squre error) at epoch 1:18851.4140625\n",
      "Training loss (Mean squre error) at epoch 3:17702.17578125\n",
      "Validation loss (Mean squre error) at epoch 3:17702.17578125\n",
      "Training loss (Mean squre error) at epoch 5:16129.3720703125\n",
      "Validation loss (Mean squre error) at epoch 5:16129.3720703125\n",
      "Training loss (Mean squre error) at epoch 7:14479.2724609375\n",
      "Validation loss (Mean squre error) at epoch 7:14479.2724609375\n",
      "Training loss (Mean squre error) at epoch 9:13107.0986328125\n",
      "Validation loss (Mean squre error) at epoch 9:13107.0986328125\n",
      "Mean Absolute Error: 51.8416\n"
     ]
    }
   ],
   "source": [
    "#Training session\n",
    "init = tf.global_variables_initializer()\n",
    "init_local = tf.local_variables_initializer() \n",
    "\n",
    "#Operation to create mini-batches of shuffled data\n",
    "\n",
    "#Select which model to use\n",
    "loss = loss1\n",
    "train_step = train_step1\n",
    "MAE = MAE1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run([init,init_local])\n",
    "    for i in range(epochs):\n",
    "        for j in range(int(len(X_train)/mini_batch_size)):\n",
    "            X1,y1 = shuffle(X_train,y_train, n_samples=mini_batch_size)\n",
    "            sess.run(train_step,feed_dict={X:X1,Y:y1})\n",
    "        #sess.run(train_step,feed_dict={X:X_train,Y:y_train})\n",
    "        if i%display_epoch ==0:\n",
    "            training_loss = sess.run(loss,feed_dict={X:X_train,Y:y_train})\n",
    "            validation_loss = sess.run(loss,feed_dict={X:X_valid,Y:y_valid})\n",
    "            print(\"Training loss (Mean squre error) at epoch {}:{}\".format(i+1,training_loss))\n",
    "            print(\"Validation loss (Mean squre error) at epoch {}:{}\".format(i+1,training_loss))\n",
    "    _,mae = sess.run(MAE,feed_dict={X:X_train,Y:y_train})\n",
    "    print(\"Mean Absolute Error:\",mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted load for input vector [  21.29         18.6           5.77        753.9666667     2.66666667]:[ 13.39552879]\n",
      "Actual value is [60] and Mean Absolute Error is 46.604469299316406\n"
     ]
    }
   ],
   "source": [
    "#Inference session\n",
    "with tf.Session() as sess:\n",
    "    sess.run([init,init_local])\n",
    "    index = random.randint(0, len(X_valid))  #Find random input vector from dataset \n",
    "    prediction,mae = sess.run([prediction1,MAE],feed_dict={X:X_valid[index].reshape(1,5),Y:y_valid[index].reshape(1,1)})\n",
    "    print(\"Predicted load for input vector {}:{}\".format(X_valid[index,:],*prediction))\n",
    "    print(\"Actual value is {} and Mean Absolute Error is {}\".format(y_valid[index],mae[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "InputLayer (InputLayer)      (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "FeedForward1 (Dense)         (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "FeedForward2 (Dense)         (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "OutputLayer (Dense)          (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 201\n",
      "Trainable params: 191\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#reset earlier graphs\n",
    "tf.reset_default_graph() \n",
    "\n",
    "#Building and training a single layer model using Keras (Available within TensorFlow)\n",
    "model = tf.contrib.keras.models.Sequential() \n",
    "#Input Layer\n",
    "model.add(tf.contrib.keras.layers.InputLayer(input_shape=(Xfeatures,),name='InputLayer'))\n",
    "model.add(tf.contrib.keras.layers.BatchNormalization(axis=1))  #Normalizing values\n",
    "#model.add(tf.contrib.keras.layers.Lambda(normalize_data ,name='Normalizing'))  #Normalizing values\n",
    "#Layer1 \n",
    "model.add(tf.contrib.keras.layers.Dense(units=L1,activation='relu',name='FeedForward1'))  #Add a feed forward layer\n",
    "#Layer2 \n",
    "model.add(tf.contrib.keras.layers.Dense(units=L1,activation='relu',name='FeedForward2'))  #Add a feed forward layer\n",
    "#Output layer \n",
    "model.add(tf.contrib.keras.layers.Dense(units=Yfeatures,name='OutputLayer'))\n",
    "\n",
    "#Specify los function and optimizer\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['mae'])\n",
    "\n",
    "#Summarize model\n",
    "model.summary()\n",
    "#Callbacks\n",
    "tb_callback = tf.contrib.keras.callbacks.TensorBoard(log_dir='./logs',histogram_freq=2,write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15788 samples, validate on 3947 samples\n",
      "Epoch 1/10\n",
      "15788/15788 [==============================] - 1s - loss: 9873.6254 - mean_absolute_error: 57.9533 - val_loss: 10646.9941 - val_mean_absolute_error: 58.9535\n",
      "Epoch 2/10\n",
      "15788/15788 [==============================] - 0s - loss: 9874.9814 - mean_absolute_error: 57.3347 - val_loss: 10635.7632 - val_mean_absolute_error: 60.6774\n",
      "Epoch 3/10\n",
      "15788/15788 [==============================] - 1s - loss: 9869.3934 - mean_absolute_error: 57.7132 - val_loss: 10634.7616 - val_mean_absolute_error: 59.0824\n",
      "Epoch 4/10\n",
      "15788/15788 [==============================] - 0s - loss: 9859.1671 - mean_absolute_error: 57.3788 - val_loss: 10626.9434 - val_mean_absolute_error: 60.7168\n",
      "Epoch 5/10\n",
      "15788/15788 [==============================] - 1s - loss: 9869.5264 - mean_absolute_error: 57.9836 - val_loss: 10621.7771 - val_mean_absolute_error: 59.1147\n",
      "Epoch 6/10\n",
      "15788/15788 [==============================] - 0s - loss: 9856.1340 - mean_absolute_error: 57.3337 - val_loss: 10611.4806 - val_mean_absolute_error: 60.2248\n",
      "Epoch 7/10\n",
      "15788/15788 [==============================] - 1s - loss: 9852.0477 - mean_absolute_error: 57.6697 - val_loss: 10609.4473 - val_mean_absolute_error: 58.8008\n",
      "Epoch 8/10\n",
      "15788/15788 [==============================] - 0s - loss: 9837.4399 - mean_absolute_error: 57.1898 - val_loss: 10601.3319 - val_mean_absolute_error: 59.1953\n",
      "Epoch 9/10\n",
      "15788/15788 [==============================] - 1s - loss: 9839.6223 - mean_absolute_error: 57.6595 - val_loss: 10592.2472 - val_mean_absolute_error: 59.5432\n",
      "Epoch 10/10\n",
      "15788/15788 [==============================] - 0s - loss: 9842.2010 - mean_absolute_error: 57.7119 - val_loss: 10610.2743 - val_mean_absolute_error: 57.4733\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "# Start Training model\n",
    "model.fit(X_train,y_train,batch_size=mini_batch_size,epochs=epochs,validation_data=(X_valid,y_valid),shuffle =True,callbacks=[tb_callback],verbose=1)\n",
    "#,callbacks=[tb_callback],\n",
    "#,validation_split = 0.2\n",
    "model.save('demo.h5')\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 105.66149902],\n",
       "       [ 135.91659546],\n",
       "       [ 132.8243103 ],\n",
       "       ..., \n",
       "       [  71.93901825],\n",
       "       [  71.56589508],\n",
       "       [  95.65309143]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inference session\n",
    "model.predict(X_valid,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted load for input vector [  22.2         21.6          8.77       751.1333333    7.       ]:[ 105.66149902]\n",
      "Actual value is [400] and  Absolute Error is [ 294.33850098]\n"
     ]
    }
   ],
   "source": [
    "#Inference session\n",
    "index = random.randint(0, len(X_valid))  #Find random input vector from dataset \n",
    "prediction = model.predict(X_valid,batch_size=1) #Find predicted value on random data set\n",
    "print(\"Predicted load for input vector {}:{}\".format(X_valid[index],*prediction))\n",
    "print(\"Actual value is {} and  Absolute Error is {}\".format(y_valid[index],abs(prediction[0]-y_valid[index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tensorboard\n",
    "#tensorboard --logdir=C:\\TensorFlow_tutorial\\logs"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
