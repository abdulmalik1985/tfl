{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define function to extract data from file, Load training data and convert into Numpy array\n",
    "def get_data(file_name):\n",
    "    df_input=pd.read_csv(file_name,usecols =['T_out','Press_mm_hg','Windspeed'])\n",
    "    df_target=pd.read_csv(file_name,usecols =['Appliances'])\n",
    "    print(df_input.info())\n",
    "    print(df_target.info())\n",
    "    X_train = df_input.as_matrix()\n",
    "    y_train = df_target.as_matrix()\n",
    "    X_train.astype('float32', copy=False)\n",
    "    y_train.astype('float32', copy=False)\n",
    "    return X_train,y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19735 entries, 0 to 19734\n",
      "Data columns (total 3 columns):\n",
      "T_out          19735 non-null float64\n",
      "Press_mm_hg    19735 non-null float64\n",
      "Windspeed      19735 non-null float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 462.6 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19735 entries, 0 to 19734\n",
      "Data columns (total 1 columns):\n",
      "Appliances    19735 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 154.3 KB\n",
      "None\n",
      "Shape of input data set (19735, 3)\n",
      "Shape of target data set (19735, 1)\n",
      "Number of samples: 19735\n"
     ]
    }
   ],
   "source": [
    "#Get training data\n",
    "file_name = './Appliances_energy_prediction_data_set_UCI.csv'\n",
    "X_train,y_train = get_data(file_name)\n",
    "print('Shape of input data set',X_train.shape)\n",
    "print('Shape of target data set',y_train.shape)\n",
    "print('Number of samples:',len(X_train))\n",
    "X_train_reshape = np.resize(X_train,(19735,2))\n",
    "y_train_reshape = np.resize(y_train,(19735,1))\n",
    "#print(X_train_reshape.shape)\n",
    "#print(y_train_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   6.48      ,  733.6       ,    6.66666667])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1,:]\n",
    "#y_train[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to normalize input data along features\n",
    "def normalize_data(raw_data):\n",
    "    import tensorflow as tf\n",
    "    return tf.nn.l2_normalize(raw_data,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training parametres\n",
    "epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Network Parameteres\n",
    "L1 = 10 # Number of neurons in Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Placeholders for input and output\n",
    "Xfeatures = 3\n",
    "Yfeatures =1\n",
    "#Input\n",
    "X = tf.placeholder(tf.float32,shape=(None,Xfeatures))#Place holder for input data\n",
    "#Output\n",
    "Y = tf.placeholder(tf.float32,shape=(None,Yfeatures))   #Place holder for target output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Builda single layer model using basic TensorFlow operations\n",
    "def FFNN_using_core(Xinput):          #Function containing FFNN model\n",
    "    #Layer1 \n",
    "    W_fc1 = tf.Variable(tf.random_uniform([Xfeatures,L1])) # Weights\n",
    "    b_fc1 = tf.Variable(tf.random_uniform([L1]))        #Biases\n",
    "    matmul_fc1=tf.matmul(Xinput, W_fc1) + b_fc1                #Matrix multiplication and additon\n",
    "    h_fc1 = tf.nn.relu(matmul_fc1)   #ReLU activation function\n",
    "\n",
    "    #Output layer \n",
    "    W_fO= tf.Variable(tf.random_uniform([L1,Yfeatures])) #  # Weights\n",
    "    b_fO = tf.Variable(tf.random_uniform([Yfeatures]))    #Biases\n",
    "    matmul_fcO=tf.matmul(h_fc1, W_fO) + b_fO    #Matrix multiplication and additon\n",
    "    output_layer = matmul_fcO  #linear activation\n",
    "    return output_layer\n",
    "\n",
    "prediction1 = FFNN_using_core(normalize_data(X))       #Call function containing for model\n",
    "#prediction = FFNN_using_core(X)       #Call function\n",
    "MAE1= tf.metrics.mean_absolute_error(Y,prediction1)   #Function to calculate mean absolute error \n",
    "\n",
    "#Loss function\n",
    "loss1 = tf.reduce_mean(tf.square(Y-prediction1))\n",
    "\n",
    "#Specify optimizer\n",
    "train_step1 = tf.train.AdamOptimizer(learning_rate).minimize(loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Build single layer model using TensorFlow layers\n",
    "def FFNN_using_layer(Xinput):          #Function containing FFNN model\n",
    "    #Layer1 \n",
    "    FC1 = tf.layers.dense(Xinput,L1,activation=tf.nn.relu)\n",
    "\n",
    "    #Output layer \n",
    "    output_layer = tf.layers.dense(FC1,Yfeatures)\n",
    "    return output_layer\n",
    "\n",
    "prediction2 = FFNN_using_layer(normalize_data(X))       #Call function\n",
    "#prediction = FFNN_using_layer(X)       #Call function\n",
    "MAE2= tf.metrics.mean_absolute_error(Y,prediction2)\n",
    "#Specify Loss function\n",
    "loss2 = tf.losses.mean_squared_error (Y,prediction2)\n",
    "#Specify optimizer\n",
    "train_step2 = tf.train.AdamOptimizer(learning_rate).minimize(loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 1:19422.548828125\n",
      "Training loss at epoch 2:19420.2890625\n",
      "Training loss at epoch 3:19417.935546875\n",
      "Training loss at epoch 4:19415.56640625\n",
      "Training loss at epoch 5:19413.318359375\n",
      "Training loss at epoch 6:19411.123046875\n",
      "Training loss at epoch 7:19409.0078125\n",
      "Training loss at epoch 8:19406.767578125\n",
      "Training loss at epoch 9:19404.353515625\n",
      "Training loss at epoch 10:19401.986328125\n",
      "Mean Absolute Error: 97.6954\n"
     ]
    }
   ],
   "source": [
    "#Training session\n",
    "init = tf.global_variables_initializer()\n",
    "init_local = tf.local_variables_initializer() \n",
    "with tf.Session() as sess:\n",
    "    sess.run([init,init_local])\n",
    "    for i in range(epochs):\n",
    "        training_loss,_ = sess.run([loss1,train_step1],feed_dict={X:X_train,Y:y_train})    \n",
    "        print(\"Training loss at epoch {}:{}\".format(i+1,training_loss))\n",
    "    _,mae = sess.run(MAE2,feed_dict={X:X_train,Y:y_train})\n",
    "    print(\"Mean Absolute Error:\",mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted load for input vector at index 5883 [  11.4  756.2    9.5]:[[ 10.32501793]]\n",
      "Actual value is [100] and Mean Absolute Error is 100.38203430175781\n"
     ]
    }
   ],
   "source": [
    "#Inference session\n",
    "with tf.Session() as sess:\n",
    "    sess.run([init,init_local])\n",
    "    index = random.randint(0, len(X_train))  #Find random input vector from dataset \n",
    "    prediction = sess.run(prediction1,feed_dict={X:[X_train[index,:]],Y:[y_train[index,:]]})\n",
    "    print(\"Predicted load for input vector at index {} {}:{}\".format(index,X_train[index,:],prediction))\n",
    "    _,mae = sess.run(MAE2,feed_dict={X:[X_train[index,:]],Y:[y_train[index,:]]})\n",
    "    print(\"Actual value is {} and Mean Absolute Error is {}\".format(y_train[index,:],mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "InputLayer (InputLayer)      (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "FeedForward1 (Dense)         (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "FeedForward2 (Dense)         (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "OutputLayer (Dense)          (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 173\n",
      "Trainable params: 167\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 15788 samples, validate on 3947 samples\n",
      "Epoch 1/10\n",
      "15788/15788 [==============================] - 3s - loss: 14586.5739 - mean_absolute_error: 71.2584 - val_loss: 8338.1187 - val_mean_absolute_error: 49.7841\n",
      "Epoch 2/10\n",
      "15788/15788 [==============================] - 1s - loss: 11279.0188 - mean_absolute_error: 61.5805 - val_loss: 8274.6015 - val_mean_absolute_error: 58.0482\n",
      "Epoch 3/10\n",
      "15788/15788 [==============================] - 1s - loss: 11052.2495 - mean_absolute_error: 61.9619 - val_loss: 8347.8314 - val_mean_absolute_error: 60.5446\n",
      "Epoch 4/10\n",
      "15788/15788 [==============================] - 1s - loss: 10939.4096 - mean_absolute_error: 61.8169 - val_loss: 8304.2983 - val_mean_absolute_error: 60.5643\n",
      "Epoch 5/10\n",
      "15788/15788 [==============================] - 1s - loss: 10943.4609 - mean_absolute_error: 61.7590 - val_loss: 8694.0125 - val_mean_absolute_error: 65.6834\n",
      "Epoch 6/10\n",
      "15788/15788 [==============================] - 1s - loss: 10924.6290 - mean_absolute_error: 61.8356 - val_loss: 8588.5309 - val_mean_absolute_error: 64.6960\n",
      "Epoch 7/10\n",
      "15788/15788 [==============================] - 1s - loss: 10920.5422 - mean_absolute_error: 61.7791 - val_loss: 8708.8831 - val_mean_absolute_error: 66.3010\n",
      "Epoch 8/10\n",
      "15788/15788 [==============================] - 1s - loss: 10920.9957 - mean_absolute_error: 61.8689 - val_loss: 8725.4352 - val_mean_absolute_error: 66.5364\n",
      "Epoch 9/10\n",
      "15788/15788 [==============================] - 1s - loss: 10906.4171 - mean_absolute_error: 61.7282 - val_loss: 8807.4683 - val_mean_absolute_error: 67.4431\n",
      "Epoch 10/10\n",
      "15788/15788 [==============================] - 1s - loss: 10911.9812 - mean_absolute_error: 62.0221 - val_loss: 8579.1847 - val_mean_absolute_error: 64.8119\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "#Building and training a single layer model using Keras (Available within TensorFlow)\n",
    "model = tf.contrib.keras.models.Sequential() \n",
    "#Input Layer\n",
    "model.add(tf.contrib.keras.layers.InputLayer(input_shape=(Xfeatures,),name='InputLayer'))\n",
    "model.add(tf.contrib.keras.layers.BatchNormalization(axis=1))  #Normalizing values\n",
    "#model.add(tf.contrib.keras.layers.Lambda(normalize_data ,name='Normalizing'))  #Normalizing values\n",
    "#Layer1 \n",
    "model.add(tf.contrib.keras.layers.Dense(units=L1,activation='relu',name='FeedForward1'))\n",
    "model.add(tf.contrib.keras.layers.Dense(units=L1,activation='relu',name='FeedForward2'))\n",
    "#Output layer \n",
    "model.add(tf.contrib.keras.layers.Dense(units=Yfeatures,name='OutputLayer'))\n",
    "#Specify los function and optimizer\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['mae'])\n",
    "\n",
    "#Summarize model\n",
    "model.summary()\n",
    "#Callbacks\n",
    "#tb_callback = tf.contrib.keras.callbacks.TensorBoard(log_dir='./logs',histogram_freq=2,write_images=True)\n",
    "#,callbacks=[tb_callback]\n",
    "# Start Training model\n",
    "model.fit(X_train,y_train,batch_size=16,epochs=epochs,validation_split = 0.2,shuffle =True,verbose=1)\n",
    "model.save('demo.h5')\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 139.65245056],\n",
       "       [ 138.56143188],\n",
       "       [ 137.50308228],\n",
       "       ..., \n",
       "       [ 161.17932129],\n",
       "       [ 160.55427551],\n",
       "       [ 160.42619324]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inference session\n",
    "model.predict(X_train,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
